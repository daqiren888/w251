# HW7 is a fun Kaggle classroom competition.

As requested, I first create a user on the Kaggel platform. I referenced the Benchmark script to develop a model in kaggle to get the highest possible accuracy score.

Three concepts from the lab are implemented in my solution:

(1) Cosine Annealing learning rate schedule


(2) Label Smoothing



(3) muliple networks and Different Architectures

Due to time constraints, my current training result scores are between 94% -96%. The screenshots submitted now are 94.48%. I'm going to go retrograde a few times and update the results on Kaggle tonight. Wish I had more improvement.

Screenshot of my score on the leaderboard (the leaderboard can be made public).
My code *.ipynb file and the training output are on GitHub:
