{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Intro-to-Transducers.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IEkvVLVnoGRV",
        "outputId": "89672654-f398-4976-999f-64807b149a48"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive/; to attempt to forcibly remount, call drive.mount(\"/content/gdrive/\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd gdrive/MyDrive/HW12"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "44KbeHeHoYqa",
        "outputId": "32e22796-2aed-4f60-a59b-b974cd68c591"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/HW12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "id": "YRjHdku9oY5S"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "C5bhqGFNoY8-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install h5py\n",
        "!pip install typing-extensions\n",
        "!pip install wheel"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_kiD2FG0locj",
        "outputId": "7ac10fab-9f2e-4e81-998d-8c15481df02e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (3.1.0)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from h5py) (1.20.3)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py) (1.5.2)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (4.1.1)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.7/dist-packages (0.37.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall imgaug -y\n",
        "!pip install imgaug==0.2.5 "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m0y_Iw5ypSE6",
        "outputId": "57007dbf-6f54-436f-c0f9-2a89d19c06cf"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: imgaug 0.2.7\n",
            "Uninstalling imgaug-0.2.7:\n",
            "  Successfully uninstalled imgaug-0.2.7\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting imgaug==0.2.5\n",
            "  Downloading imgaug-0.2.5.tar.gz (562 kB)\n",
            "\u001b[K     |████████████████████████████████| 562 kB 7.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from imgaug==0.2.5) (1.7.3)\n",
            "Requirement already satisfied: scikit-image>=0.11.0 in /usr/local/lib/python3.7/dist-packages (from imgaug==0.2.5) (0.18.3)\n",
            "Requirement already satisfied: numpy>=1.7.0 in /usr/local/lib/python3.7/dist-packages (from imgaug==0.2.5) (1.21.6)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from imgaug==0.2.5) (1.15.0)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.11.0->imgaug==0.2.5) (2.4.1)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.11.0->imgaug==0.2.5) (1.3.0)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.11.0->imgaug==0.2.5) (7.1.2)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.11.0->imgaug==0.2.5) (3.2.2)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.11.0->imgaug==0.2.5) (2021.11.2)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.11.0->imgaug==0.2.5) (2.6.3)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug==0.2.5) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug==0.2.5) (1.4.4)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug==0.2.5) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug==0.2.5) (3.0.9)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug==0.2.5) (4.1.1)\n",
            "Building wheels for collected packages: imgaug\n",
            "  Building wheel for imgaug (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for imgaug: filename=imgaug-0.2.5-py3-none-any.whl size=561438 sha256=2a60af1f38731a16d0d03225c968eb34002e60b6e51dbe7fea11348b84ac6d66\n",
            "  Stored in directory: /root/.cache/pip/wheels/60/dd/38/d1dc2cad2b6a66dc0249261004990bccb0f27985c74ba26e49\n",
            "Successfully built imgaug\n",
            "Installing collected packages: imgaug\n",
            "Successfully installed imgaug-0.2.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "You can run either this notebook locally (if you have all the dependencies and a GPU) or on Google Colab.\n",
        "\n",
        "Instructions for setting up Colab are as follows:\n",
        "1. Open a new Python 3 notebook.\n",
        "2. Import this notebook from GitHub (File -> Upload Notebook -> \"GITHUB\" tab -> copy/paste GitHub URL)\n",
        "3. Connect to an instance with a GPU (Runtime -> Change runtime type -> select \"GPU\" for hardware accelerator)\n",
        "4. Run this cell to set up dependencies.\n",
        "5. Restart the runtime (Runtime -> Restart Runtime) for any upgraded packages to take effect\n",
        "\"\"\"\n",
        "# If you're using Google Colab and not running locally, run this cell.\n",
        "import os\n",
        "\n",
        "# Install dependencies\n",
        "!pip install wget\n",
        "!apt-get install sox libsndfile1 ffmpeg\n",
        "!pip install unidecode\n",
        "!pip install matplotlib>=3.3.2\n",
        "\n",
        "## Install NeMo\n",
        "BRANCH = 'r1.10.0'\n",
        "!python -m pip install git+https://github.com/NVIDIA/NeMo.git@$BRANCH#egg=nemo_toolkit[all]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LuH6O0u9lpSY",
        "outputId": "0d7afa94-37fe-4dde-ea0f-39f7d5500707"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: wget in /usr/local/lib/python3.7/dist-packages (3.2)\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "libsndfile1 is already the newest version (1.0.28-4ubuntu0.18.04.2).\n",
            "ffmpeg is already the newest version (7:3.4.11-0ubuntu0.1).\n",
            "sox is already the newest version (14.4.2-3ubuntu0.18.04.1).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 49 not upgraded.\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: unidecode in /usr/local/lib/python3.7/dist-packages (1.3.4)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting nemo_toolkit[all]\n",
            "  Cloning https://github.com/NVIDIA/NeMo.git (to revision r1.10.0) to /tmp/pip-install-ysbgrx1y/nemo-toolkit_5f470f7b9d1c486eb03dccc63b4b6549\n",
            "  Running command git clone -q https://github.com/NVIDIA/NeMo.git /tmp/pip-install-ysbgrx1y/nemo-toolkit_5f470f7b9d1c486eb03dccc63b4b6549\n",
            "  Running command git checkout -b r1.10.0 --track origin/r1.10.0\n",
            "  Switched to a new branch 'r1.10.0'\n",
            "  Branch 'r1.10.0' set up to track remote branch 'r1.10.0' from 'origin'.\n",
            "Requirement already satisfied: setuptools==59.5.0 in /usr/local/lib/python3.7/dist-packages (from nemo_toolkit[all]) (59.5.0)\n",
            "Requirement already satisfied: numpy>=1.21 in /usr/local/lib/python3.7/dist-packages (from nemo_toolkit[all]) (1.21.6)\n",
            "Requirement already satisfied: onnx>=1.7.0 in /usr/local/lib/python3.7/dist-packages (from nemo_toolkit[all]) (1.12.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from nemo_toolkit[all]) (2.8.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from nemo_toolkit[all]) (1.12.0+cu113)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.7/dist-packages (from nemo_toolkit[all]) (1.14.1)\n",
            "Requirement already satisfied: ruamel.yaml in /usr/local/lib/python3.7/dist-packages (from nemo_toolkit[all]) (0.17.21)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from nemo_toolkit[all]) (1.0.2)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.7/dist-packages (from nemo_toolkit[all]) (4.64.0)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.7/dist-packages (from nemo_toolkit[all]) (0.56.0)\n",
            "Requirement already satisfied: wget in /usr/local/lib/python3.7/dist-packages (from nemo_toolkit[all]) (3.2)\n",
            "Requirement already satisfied: frozendict in /usr/local/lib/python3.7/dist-packages (from nemo_toolkit[all]) (2.3.4)\n",
            "Requirement already satisfied: unidecode in /usr/local/lib/python3.7/dist-packages (from nemo_toolkit[all]) (1.3.4)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.7/dist-packages (from nemo_toolkit[all]) (0.8.1)\n",
            "Requirement already satisfied: black==19.10b0 in /usr/local/lib/python3.7/dist-packages (from nemo_toolkit[all]) (19.10b0)\n",
            "Requirement already satisfied: isort[requirements]<5 in /usr/local/lib/python3.7/dist-packages (from nemo_toolkit[all]) (4.3.21)\n",
            "Requirement already satisfied: parameterized in /usr/local/lib/python3.7/dist-packages (from nemo_toolkit[all]) (0.8.1)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.7/dist-packages (from nemo_toolkit[all]) (3.6.4)\n",
            "Requirement already satisfied: pytest-runner in /usr/local/lib/python3.7/dist-packages (from nemo_toolkit[all]) (6.0.0)\n",
            "Requirement already satisfied: sphinx in /usr/local/lib/python3.7/dist-packages (from nemo_toolkit[all]) (5.1.1)\n",
            "Requirement already satisfied: sphinxcontrib-bibtex in /usr/local/lib/python3.7/dist-packages (from nemo_toolkit[all]) (2.4.2)\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.7/dist-packages (from nemo_toolkit[all]) (0.12.21)\n",
            "Requirement already satisfied: inflect in /usr/local/lib/python3.7/dist-packages (from nemo_toolkit[all]) (2.1.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from nemo_toolkit[all]) (2022.6.2)\n",
            "Requirement already satisfied: pynini==2.1.4 in /usr/local/lib/python3.7/dist-packages (from nemo_toolkit[all]) (2.1.4)\n",
            "Requirement already satisfied: pytorch-lightning<=1.6.4,>=1.6.1 in /usr/local/lib/python3.7/dist-packages (from nemo_toolkit[all]) (1.6.4)\n",
            "Requirement already satisfied: torchmetrics>=0.4.1rc0 in /usr/local/lib/python3.7/dist-packages (from nemo_toolkit[all]) (0.9.3)\n",
            "Requirement already satisfied: transformers>=4.0.1 in /usr/local/lib/python3.7/dist-packages (from nemo_toolkit[all]) (4.21.0)\n",
            "Requirement already satisfied: webdataset<=0.1.62,>=0.1.48 in /usr/local/lib/python3.7/dist-packages (from nemo_toolkit[all]) (0.1.62)\n",
            "Requirement already satisfied: omegaconf<2.2,>=2.1.2 in /usr/local/lib/python3.7/dist-packages (from nemo_toolkit[all]) (2.1.2)\n",
            "Requirement already satisfied: hydra-core<1.2,>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from nemo_toolkit[all]) (1.1.2)\n",
            "Requirement already satisfied: pyyaml<6 in /usr/local/lib/python3.7/dist-packages (from nemo_toolkit[all]) (5.4.1)\n",
            "Requirement already satisfied: sentencepiece<1.0.0 in /usr/local/lib/python3.7/dist-packages (from nemo_toolkit[all]) (0.1.96)\n",
            "Requirement already satisfied: youtokentome>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from nemo_toolkit[all]) (1.0.6)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from nemo_toolkit[all]) (1.3.5)\n",
            "Requirement already satisfied: sacremoses>=0.0.43 in /usr/local/lib/python3.7/dist-packages (from nemo_toolkit[all]) (0.0.53)\n",
            "Requirement already satisfied: braceexpand in /usr/local/lib/python3.7/dist-packages (from nemo_toolkit[all]) (0.1.7)\n",
            "Requirement already satisfied: editdistance in /usr/local/lib/python3.7/dist-packages (from nemo_toolkit[all]) (0.5.3)\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.7/dist-packages (from nemo_toolkit[all]) (0.8.1)\n",
            "Requirement already satisfied: marshmallow in /usr/local/lib/python3.7/dist-packages (from nemo_toolkit[all]) (3.17.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from nemo_toolkit[all]) (21.3)\n",
            "Requirement already satisfied: soundfile in /usr/local/lib/python3.7/dist-packages (from nemo_toolkit[all]) (0.10.3.post1)\n",
            "Requirement already satisfied: sox in /usr/local/lib/python3.7/dist-packages (from nemo_toolkit[all]) (1.4.1)\n",
            "Requirement already satisfied: kaldi-python-io in /usr/local/lib/python3.7/dist-packages (from nemo_toolkit[all]) (1.2.2)\n",
            "Requirement already satisfied: kaldiio in /usr/local/lib/python3.7/dist-packages (from nemo_toolkit[all]) (2.17.2)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from nemo_toolkit[all]) (1.7.3)\n",
            "Requirement already satisfied: g2p_en in /usr/local/lib/python3.7/dist-packages (from nemo_toolkit[all]) (2.1.0)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.7/dist-packages (from nemo_toolkit[all]) (0.25.1)\n",
            "Requirement already satisfied: pyannote.core in /usr/local/lib/python3.7/dist-packages (from nemo_toolkit[all]) (4.4)\n",
            "Requirement already satisfied: pyannote.metrics in /usr/local/lib/python3.7/dist-packages (from nemo_toolkit[all]) (3.2.1)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.7/dist-packages (from nemo_toolkit[all]) (7.7.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from nemo_toolkit[all]) (3.2.2)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from nemo_toolkit[all]) (7.1.2)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from nemo_toolkit[all]) (0.13.0+cu113)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.7/dist-packages (from nemo_toolkit[all]) (1.24.40)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from nemo_toolkit[all]) (3.1.0)\n",
            "Collecting matplotlib>=3.3.2\n",
            "  Using cached matplotlib-3.5.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (11.2 MB)\n",
            "Requirement already satisfied: rapidfuzz in /usr/local/lib/python3.7/dist-packages (from nemo_toolkit[all]) (2.3.0)\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.7/dist-packages (from nemo_toolkit[all]) (4.4.0)\n",
            "Requirement already satisfied: sacrebleu[ja] in /usr/local/lib/python3.7/dist-packages (from nemo_toolkit[all]) (2.2.0)\n",
            "Requirement already satisfied: nltk>=3.6.5 in /usr/local/lib/python3.7/dist-packages (from nemo_toolkit[all]) (3.7)\n",
            "Requirement already satisfied: fasttext in /usr/local/lib/python3.7/dist-packages (from nemo_toolkit[all]) (0.9.2)\n",
            "Requirement already satisfied: opencc in /usr/local/lib/python3.7/dist-packages (from nemo_toolkit[all]) (1.1.4)\n",
            "Requirement already satisfied: pangu in /usr/local/lib/python3.7/dist-packages (from nemo_toolkit[all]) (4.0.6.1)\n",
            "Requirement already satisfied: jieba in /usr/local/lib/python3.7/dist-packages (from nemo_toolkit[all]) (0.42.1)\n",
            "Requirement already satisfied: ftfy in /usr/local/lib/python3.7/dist-packages (from nemo_toolkit[all]) (6.1.1)\n",
            "Requirement already satisfied: flask_restful in /usr/local/lib/python3.7/dist-packages (from nemo_toolkit[all]) (0.3.9)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.7/dist-packages (from nemo_toolkit[all]) (0.4.1)\n",
            "Requirement already satisfied: ijson in /usr/local/lib/python3.7/dist-packages (from nemo_toolkit[all]) (3.1.4)\n",
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.7/dist-packages (from nemo_toolkit[all]) (1.7.2)\n",
            "Requirement already satisfied: sentence_transformers in /usr/local/lib/python3.7/dist-packages (from nemo_toolkit[all]) (2.2.2)\n",
            "Requirement already satisfied: pypinyin in /usr/local/lib/python3.7/dist-packages (from nemo_toolkit[all]) (0.46.0)\n",
            "Requirement already satisfied: attrdict in /usr/local/lib/python3.7/dist-packages (from nemo_toolkit[all]) (2.0.1)\n",
            "Requirement already satisfied: pystoi in /usr/local/lib/python3.7/dist-packages (from nemo_toolkit[all]) (0.3.3)\n",
            "Requirement already satisfied: pesq in /usr/local/lib/python3.7/dist-packages (from nemo_toolkit[all]) (0.0.4)\n",
            "Requirement already satisfied: toml>=0.9.4 in /usr/local/lib/python3.7/dist-packages (from black==19.10b0->nemo_toolkit[all]) (0.10.2)\n",
            "Requirement already satisfied: attrs>=18.1.0 in /usr/local/lib/python3.7/dist-packages (from black==19.10b0->nemo_toolkit[all]) (21.4.0)\n",
            "Requirement already satisfied: click>=6.5 in /usr/local/lib/python3.7/dist-packages (from black==19.10b0->nemo_toolkit[all]) (7.1.2)\n",
            "Requirement already satisfied: typed-ast>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from black==19.10b0->nemo_toolkit[all]) (1.5.4)\n",
            "Requirement already satisfied: pathspec<1,>=0.6 in /usr/local/lib/python3.7/dist-packages (from black==19.10b0->nemo_toolkit[all]) (0.9.0)\n",
            "Requirement already satisfied: appdirs in /usr/local/lib/python3.7/dist-packages (from black==19.10b0->nemo_toolkit[all]) (1.4.4)\n",
            "Requirement already satisfied: Cython>=0.29 in /usr/local/lib/python3.7/dist-packages (from pynini==2.1.4->nemo_toolkit[all]) (0.29.30)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.8 in /usr/local/lib/python3.7/dist-packages (from hydra-core<1.2,>=1.1.0->nemo_toolkit[all]) (4.8)\n",
            "Requirement already satisfied: importlib-resources<5.3 in /usr/local/lib/python3.7/dist-packages (from hydra-core<1.2,>=1.1.0->nemo_toolkit[all]) (5.2.3)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources<5.3->hydra-core<1.2,>=1.1.0->nemo_toolkit[all]) (3.8.1)\n",
            "Requirement already satisfied: pipreqs in /usr/local/lib/python3.7/dist-packages (from isort[requirements]<5->nemo_toolkit[all]) (0.4.11)\n",
            "Requirement already satisfied: pip-api in /usr/local/lib/python3.7/dist-packages (from isort[requirements]<5->nemo_toolkit[all]) (0.0.30)\n",
            "Requirement already satisfied: protobuf<=3.20.1,>=3.12.2 in /usr/local/lib/python3.7/dist-packages (from onnx>=1.7.0->nemo_toolkit[all]) (3.17.3)\n",
            "Requirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.7/dist-packages (from onnx>=1.7.0->nemo_toolkit[all]) (4.1.1)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf<=3.20.1,>=3.12.2->onnx>=1.7.0->nemo_toolkit[all]) (1.15.0)\n",
            "Requirement already satisfied: fsspec[http]!=2021.06.0,>=2021.05.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning<=1.6.4,>=1.6.1->nemo_toolkit[all]) (2022.7.1)\n",
            "Requirement already satisfied: pyDeprecate>=0.3.1 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning<=1.6.4,>=1.6.1->nemo_toolkit[all]) (0.3.2)\n",
            "Requirement already satisfied: tensorboard>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning<=1.6.4,>=1.6.1->nemo_toolkit[all]) (2.8.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning<=1.6.4,>=1.6.1->nemo_toolkit[all]) (2.23.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning<=1.6.4,>=1.6.1->nemo_toolkit[all]) (3.8.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->nemo_toolkit[all]) (3.0.9)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses>=0.0.43->nemo_toolkit[all]) (1.1.0)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning<=1.6.4,>=1.6.1->nemo_toolkit[all]) (1.47.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning<=1.6.4,>=1.6.1->nemo_toolkit[all]) (0.37.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning<=1.6.4,>=1.6.1->nemo_toolkit[all]) (1.8.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning<=1.6.4,>=1.6.1->nemo_toolkit[all]) (1.2.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning<=1.6.4,>=1.6.1->nemo_toolkit[all]) (0.4.6)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning<=1.6.4,>=1.6.1->nemo_toolkit[all]) (1.35.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning<=1.6.4,>=1.6.1->nemo_toolkit[all]) (0.6.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning<=1.6.4,>=1.6.1->nemo_toolkit[all]) (3.4.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning<=1.6.4,>=1.6.1->nemo_toolkit[all]) (1.0.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning<=1.6.4,>=1.6.1->nemo_toolkit[all]) (4.9)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning<=1.6.4,>=1.6.1->nemo_toolkit[all]) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning<=1.6.4,>=1.6.1->nemo_toolkit[all]) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning<=1.6.4,>=1.6.1->nemo_toolkit[all]) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning<=1.6.4,>=1.6.1->nemo_toolkit[all]) (4.12.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning<=1.6.4,>=1.6.1->nemo_toolkit[all]) (0.4.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning<=1.6.4,>=1.6.1->nemo_toolkit[all]) (2022.6.15)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning<=1.6.4,>=1.6.1->nemo_toolkit[all]) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning<=1.6.4,>=1.6.1->nemo_toolkit[all]) (1.25.11)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning<=1.6.4,>=1.6.1->nemo_toolkit[all]) (3.0.4)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning<=1.6.4,>=1.6.1->nemo_toolkit[all]) (3.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers>=4.0.1->nemo_toolkit[all]) (3.7.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers>=4.0.1->nemo_toolkit[all]) (0.12.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning<=1.6.4,>=1.6.1->nemo_toolkit[all]) (6.0.2)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning<=1.6.4,>=1.6.1->nemo_toolkit[all]) (2.1.0)\n",
            "Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning<=1.6.4,>=1.6.1->nemo_toolkit[all]) (0.13.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning<=1.6.4,>=1.6.1->nemo_toolkit[all]) (4.0.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning<=1.6.4,>=1.6.1->nemo_toolkit[all]) (1.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning<=1.6.4,>=1.6.1->nemo_toolkit[all]) (1.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning<=1.6.4,>=1.6.1->nemo_toolkit[all]) (1.7.2)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from boto3->nemo_toolkit[all]) (1.0.1)\n",
            "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from boto3->nemo_toolkit[all]) (0.6.0)\n",
            "Requirement already satisfied: botocore<1.28.0,>=1.27.40 in /usr/local/lib/python3.7/dist-packages (from boto3->nemo_toolkit[all]) (1.27.40)\n",
            "Requirement already satisfied: pybind11>=2.2 in /usr/local/lib/python3.7/dist-packages (from fasttext->nemo_toolkit[all]) (2.10.0)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from flask_restful->nemo_toolkit[all]) (2022.1)\n",
            "Requirement already satisfied: aniso8601>=0.82 in /usr/local/lib/python3.7/dist-packages (from flask_restful->nemo_toolkit[all]) (9.0.1)\n",
            "Requirement already satisfied: Flask>=0.8 in /usr/local/lib/python3.7/dist-packages (from flask_restful->nemo_toolkit[all]) (1.1.4)\n",
            "Requirement already satisfied: itsdangerous<2.0,>=0.24 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask_restful->nemo_toolkit[all]) (1.1.0)\n",
            "Requirement already satisfied: Jinja2<3.0,>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask_restful->nemo_toolkit[all]) (2.11.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2<3.0,>=2.10.1->Flask>=0.8->flask_restful->nemo_toolkit[all]) (2.0.1)\n",
            "Requirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.7/dist-packages (from ftfy->nemo_toolkit[all]) (0.2.5)\n",
            "Requirement already satisfied: distance>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from g2p_en->nemo_toolkit[all]) (0.1.3)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from gdown->nemo_toolkit[all]) (4.6.3)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->nemo_toolkit[all]) (1.5.2)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->nemo_toolkit[all]) (5.1.1)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->nemo_toolkit[all]) (1.1.1)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->nemo_toolkit[all]) (5.5.0)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->nemo_toolkit[all]) (0.2.0)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->nemo_toolkit[all]) (3.6.1)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->nemo_toolkit[all]) (4.10.1)\n",
            "Requirement already satisfied: tornado>=4.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel>=4.5.1->ipywidgets->nemo_toolkit[all]) (5.1.1)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.7/dist-packages (from ipykernel>=4.5.1->ipywidgets->nemo_toolkit[all]) (5.3.5)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets->nemo_toolkit[all]) (4.8.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets->nemo_toolkit[all]) (2.6.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets->nemo_toolkit[all]) (4.4.2)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets->nemo_toolkit[all]) (1.0.18)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets->nemo_toolkit[all]) (0.8.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets->nemo_toolkit[all]) (0.7.5)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.7/dist-packages (from widgetsnbextension~=3.6.0->ipywidgets->nemo_toolkit[all]) (5.3.1)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->nemo_toolkit[all]) (5.4.0)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->nemo_toolkit[all]) (5.6.1)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->nemo_toolkit[all]) (1.8.0)\n",
            "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->nemo_toolkit[all]) (0.13.3)\n",
            "Requirement already satisfied: jupyter-core>=4.4.0 in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->nemo_toolkit[all]) (4.11.1)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.7/dist-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets->nemo_toolkit[all]) (23.2.0)\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.7/dist-packages (from terminado>=0.8.1->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->nemo_toolkit[all]) (0.7.0)\n",
            "Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa->nemo_toolkit[all]) (2.1.9)\n",
            "Requirement already satisfied: resampy>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from librosa->nemo_toolkit[all]) (0.3.1)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.7/dist-packages (from librosa->nemo_toolkit[all]) (1.6.0)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.7/dist-packages (from numba->nemo_toolkit[all]) (0.39.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->nemo_toolkit[all]) (3.1.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.7/dist-packages (from soundfile->nemo_toolkit[all]) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.0->soundfile->nemo_toolkit[all]) (2.21)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->nemo_toolkit[all]) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->nemo_toolkit[all]) (1.4.4)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->nemo_toolkit[all]) (1.5.0)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->nemo_toolkit[all]) (0.8.4)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->nemo_toolkit[all]) (0.4)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->nemo_toolkit[all]) (0.6.0)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->nemo_toolkit[all]) (5.0.1)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->nemo_toolkit[all]) (0.7.1)\n",
            "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.7/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->nemo_toolkit[all]) (2.16.1)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.7/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->nemo_toolkit[all]) (4.3.3)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->nemo_toolkit[all]) (0.18.1)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->nemo_toolkit[all]) (0.5.1)\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.7/dist-packages (from pip-api->isort[requirements]<5->nemo_toolkit[all]) (21.1.3)\n",
            "Requirement already satisfied: docopt in /usr/local/lib/python3.7/dist-packages (from pipreqs->isort[requirements]<5->nemo_toolkit[all]) (0.6.2)\n",
            "Requirement already satisfied: yarg in /usr/local/lib/python3.7/dist-packages (from pipreqs->isort[requirements]<5->nemo_toolkit[all]) (0.1.9)\n",
            "Requirement already satisfied: sortedcontainers>=2.0.4 in /usr/local/lib/python3.7/dist-packages (from pyannote.core->nemo_toolkit[all]) (2.4.0)\n",
            "Requirement already satisfied: simplejson>=3.8.1 in /usr/local/lib/python3.7/dist-packages (from pyannote.core->nemo_toolkit[all]) (3.17.6)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.7/dist-packages (from pyannote.metrics->nemo_toolkit[all]) (0.8.10)\n",
            "Requirement already satisfied: sympy>=1.1 in /usr/local/lib/python3.7/dist-packages (from pyannote.metrics->nemo_toolkit[all]) (1.7.1)\n",
            "Requirement already satisfied: pyannote.database>=4.0.1 in /usr/local/lib/python3.7/dist-packages (from pyannote.metrics->nemo_toolkit[all]) (4.1.3)\n",
            "Requirement already satisfied: typer[all]>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from pyannote.database>=4.0.1->pyannote.metrics->nemo_toolkit[all]) (0.4.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.7/dist-packages (from sympy>=1.1->pyannote.metrics->nemo_toolkit[all]) (1.2.1)\n",
            "Requirement already satisfied: shellingham<2.0.0,>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from typer[all]>=0.2.1->pyannote.database>=4.0.1->pyannote.metrics->nemo_toolkit[all]) (1.4.0)\n",
            "Requirement already satisfied: colorama<0.5.0,>=0.4.3 in /usr/local/lib/python3.7/dist-packages (from typer[all]>=0.2.1->pyannote.database>=4.0.1->pyannote.metrics->nemo_toolkit[all]) (0.4.5)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from pytest->nemo_toolkit[all]) (1.11.0)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from pytest->nemo_toolkit[all]) (8.13.0)\n",
            "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.7/dist-packages (from pytest->nemo_toolkit[all]) (0.7.1)\n",
            "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.7/dist-packages (from pytest->nemo_toolkit[all]) (1.4.1)\n",
            "Requirement already satisfied: jarowinkler<2.0.0,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from rapidfuzz->nemo_toolkit[all]) (1.2.0)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning<=1.6.4,>=1.6.1->nemo_toolkit[all]) (1.7.1)\n",
            "Requirement already satisfied: ruamel.yaml.clib>=0.2.6 in /usr/local/lib/python3.7/dist-packages (from ruamel.yaml->nemo_toolkit[all]) (0.2.6)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.7/dist-packages (from sacrebleu[ja]->nemo_toolkit[all]) (2.5.1)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from sacrebleu[ja]->nemo_toolkit[all]) (4.2.6)\n",
            "Requirement already satisfied: mecab-python3==1.0.5 in /usr/local/lib/python3.7/dist-packages (from sacrebleu[ja]->nemo_toolkit[all]) (1.0.5)\n",
            "Requirement already satisfied: ipadic<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from sacrebleu[ja]->nemo_toolkit[all]) (1.0.0)\n",
            "Requirement already satisfied: sphinxcontrib-htmlhelp>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from sphinx->nemo_toolkit[all]) (2.0.0)\n",
            "Requirement already satisfied: sphinxcontrib-serializinghtml>=1.1.5 in /usr/local/lib/python3.7/dist-packages (from sphinx->nemo_toolkit[all]) (1.1.5)\n",
            "Requirement already satisfied: sphinxcontrib-jsmath in /usr/local/lib/python3.7/dist-packages (from sphinx->nemo_toolkit[all]) (1.0.1)\n",
            "Requirement already satisfied: sphinxcontrib-qthelp in /usr/local/lib/python3.7/dist-packages (from sphinx->nemo_toolkit[all]) (1.0.3)\n",
            "Requirement already satisfied: snowballstemmer>=1.1 in /usr/local/lib/python3.7/dist-packages (from sphinx->nemo_toolkit[all]) (2.2.0)\n",
            "Requirement already satisfied: babel>=1.3 in /usr/local/lib/python3.7/dist-packages (from sphinx->nemo_toolkit[all]) (2.10.3)\n",
            "Requirement already satisfied: sphinxcontrib-applehelp in /usr/local/lib/python3.7/dist-packages (from sphinx->nemo_toolkit[all]) (1.0.2)\n",
            "Requirement already satisfied: imagesize in /usr/local/lib/python3.7/dist-packages (from sphinx->nemo_toolkit[all]) (1.4.1)\n",
            "Requirement already satisfied: docutils<0.20,>=0.14 in /usr/local/lib/python3.7/dist-packages (from sphinx->nemo_toolkit[all]) (0.17.1)\n",
            "Requirement already satisfied: alabaster<0.8,>=0.7 in /usr/local/lib/python3.7/dist-packages (from sphinx->nemo_toolkit[all]) (0.7.12)\n",
            "Requirement already satisfied: sphinxcontrib-devhelp in /usr/local/lib/python3.7/dist-packages (from sphinx->nemo_toolkit[all]) (1.0.2)\n",
            "Requirement already satisfied: pybtex>=0.24 in /usr/local/lib/python3.7/dist-packages (from sphinxcontrib-bibtex->nemo_toolkit[all]) (0.24.0)\n",
            "Requirement already satisfied: pybtex-docutils>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from sphinxcontrib-bibtex->nemo_toolkit[all]) (1.0.2)\n",
            "Requirement already satisfied: latexcodec>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from pybtex>=0.24->sphinxcontrib-bibtex->nemo_toolkit[all]) (2.0.1)\n",
            "Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb->nemo_toolkit[all]) (1.9.0)\n",
            "Requirement already satisfied: pathtools in /usr/local/lib/python3.7/dist-packages (from wandb->nemo_toolkit[all]) (0.1.2)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from wandb->nemo_toolkit[all]) (0.4.0)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb->nemo_toolkit[all]) (5.4.8)\n",
            "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb->nemo_toolkit[all]) (2.3)\n",
            "Requirement already satisfied: shortuuid>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from wandb->nemo_toolkit[all]) (1.0.9)\n",
            "Requirement already satisfied: GitPython>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb->nemo_toolkit[all]) (3.1.27)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.7/dist-packages (from wandb->nemo_toolkit[all]) (1.3.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb->nemo_toolkit[all]) (4.0.9)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.7/dist-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb->nemo_toolkit[all]) (5.0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nGicRAdBql2J",
        "outputId": "677103ba-de83-4b06-a1ad-0be3f1e3f59c"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (1.20.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install folium==0.2.1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DmRjKxZwrVYW",
        "outputId": "81bdf0f7-c495-484d-9fbd-bbac3812daec"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting folium==0.2.1\n",
            "  Downloading folium-0.2.1.tar.gz (69 kB)\n",
            "\u001b[K     |████████████████████████████████| 69 kB 4.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: Jinja2 in /usr/local/lib/python3.7/dist-packages (from folium==0.2.1) (2.11.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2->folium==0.2.1) (2.0.1)\n",
            "Building wheels for collected packages: folium\n",
            "  Building wheel for folium (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for folium: filename=folium-0.2.1-py3-none-any.whl size=79808 sha256=0553627d672fb2773d7c2de20fdb1f2ee7c6870931dbebb1c3ec2cc461c2c14c\n",
            "  Stored in directory: /root/.cache/pip/wheels/9a/f0/3a/3f79a6914ff5affaf50cabad60c9f4d565283283c97f0bdccf\n",
            "Successfully built folium\n",
            "Installing collected packages: folium\n",
            "  Attempting uninstall: folium\n",
            "    Found existing installation: folium 0.8.3\n",
            "    Uninstalling folium-0.8.3:\n",
            "      Successfully uninstalled folium-0.8.3\n",
            "Successfully installed folium-0.2.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ac55MjAM5cls",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93a9663f-1a0a-476a-c1b4-bdf10440d2e3"
      },
      "source": [
        "# In a conda environment, you would use the following command\n",
        "# Update Numba to > 0.53\n",
        "# conda install -c conda-forge numba\n",
        "# or\n",
        "# conda update -c conda-forge numba\n",
        "\n",
        "# For pip based environments,\n",
        "# Update Numba to > 0.54\n",
        "!pip install --upgrade numba==0.54.1"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: numba==0.54.1 in /usr/local/lib/python3.7/dist-packages (0.54.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba==0.54.1) (59.5.0)\n",
            "Requirement already satisfied: llvmlite<0.38,>=0.37.0rc1 in /usr/local/lib/python3.7/dist-packages (from numba==0.54.1) (0.37.0)\n",
            "Requirement already satisfied: numpy<1.21,>=1.17 in /usr/local/lib/python3.7/dist-packages (from numba==0.54.1) (1.20.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "lNwegSmmrTcA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dqbpRwpnQ-1D"
      },
      "source": [
        "# Intro to Transducers\n",
        "\n",
        "By following the earlier tutorials for Automatic Speech Recognition in NeMo, one would have probably noticed that we always end up using [Connectionist Temporal Classification (CTC) loss](https://distill.pub/2017/ctc/) in order to train the model. Speech Recognition can be formulated in many different ways, and CTC is a more popular approach because it is a monotonic loss - an acoustic feature at timestep $t_1$ and $t_2$ will correspond to a target token at timestep $u_1$ and only then $u_2$. This monotonic property significantly simplifies the training of ASR models and speeds up convergence. However, it has certain drawbacks that we will discuss below.\n",
        "\n",
        "In general, ASR can be described as a sequence-to-sequence prediction task - the original sequence is an audio sequence (often transformed into mel spectrograms). The target sequence is a sequence of characters (or subword tokens). Attention models are capable of the same sequence-to-sequence prediction tasks. They can even perform better than CTC due to their autoregressive decoding. However, they lack certain inductive biases that can be leveraged to stabilize and speed up training (such as the monotonicity exhibited by the CTC loss). Furthermore, by design, attention models require the entire sequence to be available to align the sequence to the output, thereby preventing their use for streaming inference.\n",
        "\n",
        "Then comes the [Transducer Loss](https://arxiv.org/abs/1211.3711). Proposed by Alex Graves, it aimed to resolve the issues in CTC loss while resolving the transcription accuracy issues by performing autoregressive decoding. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OaPS4_xSRGNv"
      },
      "source": [
        "## Drawbacks of Connectionist Temporal Classification (CTC)\n",
        "\n",
        "CTC is an excellent loss to train ASR models in a stable manner but comes with certain limitations on model design. If we presume speech recognition to be a sequence-to-sequence problem, let $T$ be the sequence length of the acoustic model's output, and let $U$ be the sequence length of the target text transcript (post tokenization, either as characters or subwords). \n",
        "\n",
        "-------\n",
        "\n",
        "1) CTC imposes the limitation : $T \\ge U$. Normally, this assumption is naturally valid because $T$ is generally a lot longer than the final text transcription. However, there are many cases where this assumption fails.\n",
        "\n",
        "- Acoustic model performs downsampling to such a degree that $T \\ge U$. Why would we want to perform so much downsampling? For convolutions, longer sequences take more stride steps and more memory. For Attention-based models (say Conformer), there's a quadratic memory cost of computing the attention step in proportion to $T$. So more downsampling significantly helps relieve the memory requirements. There are ways to bypass this limitation, as discussed in the `ASR_with_Subword_Tokenization` notebook, but even that has limits.\n",
        "\n",
        "- The target sequence is generally very long. Think of languages such as German, which have very long translations for short English words. In the task of ASR, if there is more than 2x downsampling and character tokenization is used, the model will often fail to learn due to this CTC limitation.\n",
        "\n",
        "2) Tokens predicted by models which are trained with just CTC loss are assumed to be *conditionally independent*. This means that, unlike language models where *h*-*e*-*l*-*l* as input would probably predict *o* to complete *hello*, for CTC trained models - any character from the English alphabet has equal likelihood for prediction. So CTC trained models often have misspellings or missing tokens when transcribing the audio segment to text. \n",
        "\n",
        "- Since we often use the Word Error Rate (WER) metric when evaluating models, even a single misspelling contributes significantly to the \"word\" being incorrect. \n",
        "\n",
        "- To alleviate this issue, we have to resort to Beam Search via an external language model. While this often works and significantly improves transcription accuracy, it is a slow process and involves large N-gram or Neural language models. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5EVBcBDNf658"
      },
      "source": [
        "--------\n",
        "\n",
        "Let's see CTC loss's limitation (1) in action:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4whMzIjYf4w8"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aGdKAFe7gGY4"
      },
      "source": [
        "T = 10  # acoustic sequence length\n",
        "U = 16  # target sequence length\n",
        "V = 28  # vocabulary size\n",
        "\n",
        "def get_sample(T, U, V, require_grad=True):\n",
        "  torch.manual_seed(0)\n",
        "\n",
        "  acoustic_seq = torch.randn(1, T, V + 1, requires_grad=require_grad)\n",
        "  acoustic_seq_len = torch.tensor([T], dtype=torch.int32)  # actual seq length in padded tensor (here no padding is done)\n",
        "\n",
        "  target_seq = torch.randint(low=0, high=V, size=(1, U))\n",
        "  target_seq_len = torch.tensor([U], dtype=torch.int32)\n",
        "\n",
        "  return acoustic_seq, acoustic_seq_len, target_seq, target_seq_len"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DTYIb-7ngo_L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "863db81a-09f7-47e5-f74e-b96db696d1b7"
      },
      "source": [
        "# First, we use CTC loss in the general sense.\n",
        "loss = torch.nn.CTCLoss(blank=V, zero_infinity=False)\n",
        "\n",
        "acoustic_seq, acoustic_seq_len, target_seq, target_seq_len = get_sample(T, U, V)\n",
        "\n",
        "# CTC loss expects acoustic sequence to be in shape (T, B, V)\n",
        "val = loss(acoustic_seq.transpose(1, 0), target_seq, acoustic_seq_len, target_seq_len)\n",
        "print(\"CTC Loss :\", val)\n",
        "\n",
        "val.backward()\n",
        "print(\"Grad of Acoustic model (over V):\", acoustic_seq.grad[0, 0, :])"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CTC Loss : tensor(inf, grad_fn=<MeanBackward0>)\n",
            "Grad of Acoustic model (over V): tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
            "        nan, nan, nan, nan, nan])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lBDvC2RykFC4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2563765-c141-4adf-9352-7f5c1fe3e8c4"
      },
      "source": [
        "# Next, we use CTC loss with `zero_infinity` flag set.\n",
        "loss = torch.nn.CTCLoss(blank=V, zero_infinity=True)\n",
        "\n",
        "acoustic_seq, acoustic_seq_len, target_seq, target_seq_len = get_sample(T, U, V)\n",
        "\n",
        "# CTC loss expects acoustic sequence to be in shape (T, B, V)\n",
        "val = loss(acoustic_seq.transpose(1, 0), target_seq, acoustic_seq_len, target_seq_len)\n",
        "print(\"CTC Loss :\", val)\n",
        "\n",
        "val.backward()\n",
        "print(\"Grad of Acoustic model (over V):\", acoustic_seq.grad[0, 0, :])"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CTC Loss : tensor(0., grad_fn=<MeanBackward0>)\n",
            "Grad of Acoustic model (over V): tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SQe6WYnWkSAZ"
      },
      "source": [
        "-------\n",
        "\n",
        "As we saw, CTC loss in general case will not be able to compute the loss or the gradient when $T \\ge U$. In the PyTorch specific implementation of CTC Loss, we can specify a flag `zero_infinity`, which explicitly checks for such cases, zeroes out the loss and the gradient if such a case occurs. The flag allows us to train a batch of samples where some samples may accidentally violate this limitation, but training will not halt, and gradients will not become NAN."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EGnc5HqnZ-GZ"
      },
      "source": [
        "## What is the Transducer Loss ?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0W12xF_CqcVF"
      },
      "source": [
        "![](https://github.com/NVIDIA/NeMo/blob/main/tutorials/asr/images/transducer.png?raw=true)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RoOQJtIkqxbA"
      },
      "source": [
        "A model that seeks to use the Transducer loss is composed of three models that interact with each other. They are:\n",
        "\n",
        "-------\n",
        "\n",
        "1) **Acoustic model** : This is nearly the same acoustic model used for CTC models. The output shape of these models is generally $(Batch, \\, T, \\, AM-Hidden)$. You will note that unlike for CTC, the output of the acoustic model is no longer passed through a decoder layer which would have the shape  $(Batch, \\, T, \\, Vocabulary + 1)$.\n",
        "\n",
        "2) **Prediction / Decoder model** : The prediction model accepts a sequence of target tokens (in the case of ASR, text tokens) and is usually a causal auto-regressive model that is tasked with predicting some hidden feature dimension of shape $(Batch, \\, U, \\, Pred-Hidden)$.\n",
        "\n",
        "3) **Joint model** : This model accepts the outputs of the Acoustic model and the Prediction model and joins them to compute a joint probability distribution over the vocabulary space to compute the alignments from Acoustic sequence to Target sequence. The output of this model is of the shape $(Batch, \\, T, \\, U, \\, Vocabulary + 1)$.\n",
        "\n",
        "--------\n",
        "\n",
        "During training, the transducer loss is computed on the output of the joint model, which computes the joint probability distribution of a target vocabulary token $v_{t, u}$ (for all $v \\in V$) being predicted given the acoustic feature at timestep $t \\le T$ and the prediction network features at timestep $u \\le U$.\n",
        "\n",
        "--------\n",
        "\n",
        "During inference, we perform a single forward pass over the Acoustic Network to obtain the features of shape $(Batch, \\, T, \\, AM-Hidden)$, and autoregressively perform the forward passes of the Prediction Network and the Joint Network to decode several $u \\le U$ target tokens per acoustic timestep $t \\le T$. We will discuss decoding in the following sections.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yBxtxt2Ztuoo"
      },
      "source": [
        "---------\n",
        "\n",
        "**Note**: For an excellent in-depth explanation of how Transducer loss works, how it computes the alignment, and how the gradient of this alignment is calculated, we highly encourage you to read this post about [Sequence-to-sequence learning with Transducers by Loren Lugosch](https://lorenlugosch.github.io/posts/2020/11/transducer/).\n",
        "\n",
        "---------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VgdYFkeyRGP-"
      },
      "source": [
        "## Benefits of Transducer Loss\n",
        "\n",
        "Now that we understand what a Transducer model is comprised of and how it is trained, the next question that comes to mind is - What is the benefit of the Transducer loss?\n",
        "\n",
        "------\n",
        "\n",
        "1) It is a monotonic loss (similar to CTC). Monotonicity speeds up convergence and does not require auxiliary losses to stabilize training (which is required when using only attention-based loss for sequence-to-sequence training).\n",
        "\n",
        "2) Autoregressive decoding enables the model to implicitly have a dependency between predicted tokens (the conditional independence assumption of CTC trained models is corrected). As such, missing characters or incorrect spellings are less frequent (but still exist since no model is perfect).\n",
        "\n",
        "3) It no longer has the $T \\ge U$ limitation that CTC imposed. This is because the total joint probability distribution is calculated now - mapping every acoustic timestep $t \\le T$ to one or more target timestep $u \\le U$. This means that for each timestep $t$, the model has at most $U$ tokens that it can predict, and therefore in the extreme case, it can predict a total of $T \\times U$ tokens!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wisUfV8aRGSY"
      },
      "source": [
        "## Drawbacks of Transducer Loss\n",
        "\n",
        "All of these benefits come with certain costs. As is (almost) always the case in machine learning, there is no free lunch. \n",
        "\n",
        "-------\n",
        "\n",
        "1) During training, the Joint model is required to compute a joint matrix of shape $(Batch, \\, T, \\, U, \\, Vocabulary + 1)$. If you consider the value of these constants for a general dataset like Librispeech, $T \\sim 1600$, $U \\sim 450$ (with character encoding) and vocabulary $V \\sim 28+1$. Considering a batch size of 32, that total memory cost comes out to roughly **2.7 GB** at float precision. The model would also need another **2.7 GB** for the gradients. Of course, the model needs more memory still for the actual Acoustic model + Prediction model + their gradients. Note, however - this issue can be *partially* resolved with some simple tricks, which are discussed in the next tutorial. Also, this memory cost is no longer an issue during inference!\n",
        "\n",
        "2) Autoregressive decoding is slow. Much slower than CTC models, which require just a simple argmax of the output tensor. So while we do get superior transcription quality, we sacrifice decoding speed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RuASpPlD2con"
      },
      "source": [
        "--------\n",
        "\n",
        "Let's check that RNNT loss no longer shows the limitations of CTC loss - "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XXodnve02c8h"
      },
      "source": [
        "T = 10  # acoustic sequence length\n",
        "U = 16  # target sequence length\n",
        "V = 28  # vocabulary size\n",
        "\n",
        "def get_rnnt_sample(T, U, V, require_grad=True):\n",
        "  torch.manual_seed(0)\n",
        "\n",
        "  joint_tensor = torch.randn(1, T, U + 1, V + 1, requires_grad=require_grad)\n",
        "  acoustic_seq_len = torch.tensor([T], dtype=torch.int32)  # actual seq length in padded tensor (here no padding is done)\n",
        "\n",
        "  target_seq = torch.randint(low=0, high=V, size=(1, U))\n",
        "  target_seq_len = torch.tensor([U], dtype=torch.int32)\n",
        "\n",
        "  return joint_tensor, acoustic_seq_len, target_seq, target_seq_len"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-9Qx01G21oK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "063900d8-0db2-4cd2-981e-1f837bde78a6"
      },
      "source": [
        "import nemo.collections.asr as nemo_asr"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2022-07-29 06:40:41 optimizers:55] Apex was not found. Using the lamb or fused_adam optimizer will error out.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6hb7q81f21qj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5db50e73-e2f7-4860-b6d3-3afca58e5d3f"
      },
      "source": [
        "joint_tensor, acoustic_seq_len, target_seq, target_seq_len = get_rnnt_sample(T, U, V)\n",
        "\n",
        "# RNNT loss expects joint tensor to be in shape (B, T, U, V)\n",
        "loss = nemo_asr.losses.rnnt.RNNTLoss(num_classes=V)\n",
        "\n",
        "# Uncomment to check out the keyword arguments required to call the RNNT loss\n",
        "print(\"Transducer loss input types :\", loss.input_types)\n",
        "print()\n",
        "\n",
        "val = loss(log_probs=joint_tensor, targets=target_seq, input_lengths=acoustic_seq_len, target_lengths=target_seq_len)\n",
        "print(\"Transducer Loss :\", val)\n",
        "\n",
        "val.backward()\n",
        "print(\"Grad of Acoustic model (over V):\", joint_tensor.grad[0, 0, 0, :])"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transducer loss input types : {'log_probs': NeuralType(axis=(batch, time, time, dimension), element_type=LogprobsType), 'targets': NeuralType(axis=(batch, time), element_type=LabelsType), 'input_lengths': NeuralType(axis=(batch,), element_type=LengthsType), 'target_lengths': NeuralType(axis=(batch,), element_type=LengthsType)}\n",
            "\n",
            "Transducer Loss : tensor(79.8858, grad_fn=<MeanBackward0>)\n",
            "Grad of Acoustic model (over V): tensor([ 0.0077,  0.0075,  0.0184,  0.0153,  0.0551, -0.7121,  0.0172,  0.0028,\n",
            "         0.0326,  0.0067,  0.0335,  0.0321,  0.0266,  0.0814,  0.0721,  0.0184,\n",
            "         0.0061,  0.0043,  0.0416,  0.0522,  0.0430,  0.0050,  0.0168,  0.1506,\n",
            "         0.0500,  0.0131,  0.0198,  0.0284, -0.1461])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5pfrpy7wRGUc"
      },
      "source": [
        "# Configure a Transducer Model\n",
        "\n",
        "We now understand a bit more about the transducer loss. Next, we will take a deep dive into how to set up the config for a transducer model.\n",
        "\n",
        "Transducer configs contain a fair bit more detail compared to CTC configs. However, the vast majority of the defaults can be copied and pasted into your configs to have a perfectly functioning transducer model!\n",
        "\n",
        "------\n",
        "\n",
        "Let us download one of the transducer configs already available in NeMo to analyze the components."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cgJQXfwy7LO_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7409d85-dffb-4ce1-9c1f-aa8434288f1d"
      },
      "source": [
        "import os\n",
        "\n",
        "if not os.path.exists(\"contextnet_rnnt.yaml\"):\n",
        "  !wget https://raw.githubusercontent.com/NVIDIA/NeMo/$BRANCH/examples/asr/conf/contextnet_rnnt/contextnet_rnnt.yaml"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-07-29 06:41:09--  https://raw.githubusercontent.com/NVIDIA/NeMo/r1.10.0/examples/asr/conf/contextnet_rnnt/contextnet_rnnt.yaml\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 18863 (18K) [text/plain]\n",
            "Saving to: ‘contextnet_rnnt.yaml’\n",
            "\n",
            "\rcontextnet_rnnt.yam   0%[                    ]       0  --.-KB/s               \rcontextnet_rnnt.yam 100%[===================>]  18.42K  --.-KB/s    in 0.004s  \n",
            "\n",
            "2022-07-29 06:41:09 (4.64 MB/s) - ‘contextnet_rnnt.yaml’ saved [18863/18863]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "JJ0FVl_zoENh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CJ2-ORS17XbF"
      },
      "source": [
        "from omegaconf import OmegaConf, open_dict\n",
        "\n",
        "cfg = OmegaConf.load('contextnet_rnnt.yaml')"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h5TsAJQk6o4N"
      },
      "source": [
        "## Model Defaults\n",
        "\n",
        "Since the transducer model is comprised of three separate models working in unison, it is practical to have some shared section of the config. That shared section is called `model.model_defaults`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N8tWZ9eb75Gx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef3b116b-13d5-475f-ecf9-59c510b20bf4"
      },
      "source": [
        "print(OmegaConf.to_yaml(cfg.model.model_defaults))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "filters: 1024\n",
            "repeat: 5\n",
            "dropout: 0.1\n",
            "separable: true\n",
            "se: true\n",
            "se_context_size: -1\n",
            "kernel_size_factor: 1.0\n",
            "enc_hidden: 640\n",
            "pred_hidden: 640\n",
            "joint_hidden: 640\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m8IxgJFj7_gc"
      },
      "source": [
        "-------\n",
        "\n",
        "Of the many components shared here, the last three values are the primary components that a transducer model **must** possess. They are :\n",
        "\n",
        "1) `enc_hidden`: The hidden dimension of the final layer of the Encoder network.\n",
        "\n",
        "2) `pred_hidden`: The hidden dimension of the final layer of the Prediction network.\n",
        "\n",
        "3) `joint_hidden`: The hidden dimension of the intermediate layer of the Joint network.\n",
        "\n",
        "--------\n",
        "\n",
        "One can access these values inside the config by using OmegaConf interpolation as follows :\n",
        "\n",
        "```yaml\n",
        "model:\n",
        "  ...\n",
        "  decoder:\n",
        "    ...\n",
        "    prednet:\n",
        "      pred_hidden: ${model.model_defaults.pred_hidden}\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uRckIz_eRGWr"
      },
      "source": [
        "## Acoustic Model\n",
        "\n",
        "As we discussed before, the transducer model is comprised of three models combined. One of these models is the Acoustic (encoder) model. We should be able to drop in any CTC Acoustic model config into this section of the transducer config.\n",
        "\n",
        "The only condition that needs to be met is that **the final layer of the acoustic model must have the dimension defined in `model_defaults.enc_hidden`**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o505IGX4RGYy"
      },
      "source": [
        "## Decoder / Prediction Model\n",
        "\n",
        "The Prediction model is generally an autoregressive, causal model that consumes text tokens and returns embeddings that will be used by the Joint model. \n",
        "\n",
        "**This config can be dropped into any custom transducer model with no modification.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A2a9Y5CCArLs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "919d2ec5-804e-4f07-f16f-7d75d7655185"
      },
      "source": [
        "print(OmegaConf.to_yaml(cfg.model.decoder))"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "_target_: nemo.collections.asr.modules.RNNTDecoder\n",
            "normalization_mode: null\n",
            "random_state_sampling: false\n",
            "blank_as_pad: true\n",
            "prednet:\n",
            "  pred_hidden: ${model.model_defaults.pred_hidden}\n",
            "  pred_rnn_layers: 1\n",
            "  t_max: null\n",
            "  dropout: 0.1\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ry5a_Z-zAvll"
      },
      "source": [
        "------\n",
        "\n",
        "This config will build an LSTM based Transducer Decoder model. Let us discuss some of the important arguments:\n",
        "\n",
        "1) `blank_as_pad`: In ordinary transducer models, the embedding matrix does not acknowledge the `Transducer Blank` token (similar to CTC Blank). However, this causes the autoregressive loop to be more complicated and less efficient. Instead, this flag which is set by default, will add the `Transducer Blank` token to the embedding matrix - and use it as a pad value (zeros tensor). This enables more efficient inference without harming training.\n",
        "\n",
        "2) `prednet.pred_hidden`: The hidden dimension of the LSTM and the output dimension of the Prediction network.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FtdYE25cW1j_"
      },
      "source": [
        "## Joint Model\n",
        "\n",
        "The Joint model is a simple feed-forward Multi-Layer Perceptron network. This MLP accepts the output of the Acoustic and Prediction models and computes a joint probability distribution over the entire vocabulary space.\n",
        "\n",
        "**This config can be dropped into any custom transducer model with no modification.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pP8fL1bED3Dv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85f514e9-ef06-4fe1-becc-ff1ad19dd3c9"
      },
      "source": [
        "print(OmegaConf.to_yaml(cfg.model.joint))"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "_target_: nemo.collections.asr.modules.RNNTJoint\n",
            "log_softmax: null\n",
            "preserve_memory: false\n",
            "fuse_loss_wer: true\n",
            "fused_batch_size: 16\n",
            "jointnet:\n",
            "  joint_hidden: ${model.model_defaults.joint_hidden}\n",
            "  activation: relu\n",
            "  dropout: 0.1\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rA11eez_FYUl"
      },
      "source": [
        "------\n",
        "\n",
        "The Joint model config has several essential components which we discuss below :\n",
        "\n",
        "1) `log_softmax`: Due to the cost of computing softmax on such large tensors, the Numba CUDA implementation of RNNT loss will implicitly compute the log softmax when called (so its inputs should be logits). The CPU version of the loss doesn't face such memory issues so it requires log-probabilities instead. Since the behaviour is different for CPU-GPU, the `None` value will automatically switch behaviour dependent on whether the input tensor is on a CPU or GPU device.\n",
        "\n",
        "2) `preserve_memory`: This flag will call `torch.cuda.empty_cache()` at certain critical sections when computing the Joint tensor. While this operation might allow us to preserve some memory, the empty_cache() operation is tremendously slow and will slow down training by an order of magnitude or more. It is available to use but not recommended.\n",
        "\n",
        "3) `fuse_loss_wer`: This flag performs \"batch splitting\" and then \"fused loss + metric\" calculation. It will be discussed in detail in the next tutorial that will train a Transducer model.\n",
        "\n",
        "4) `fused_batch_size`: When the above flag is set to True, the model will have two distinct \"batch sizes\". The batch size provided in the three data loader configs (`model.*_ds.batch_size`) will now be the `Acoustic model` batch size, whereas the `fused_batch_size` will be the batch size of the `Prediction model`, the `Joint model`, the `transducer loss` module and the `decoding` module.\n",
        "\n",
        "5) `jointnet.joint_hidden`: The hidden intermediate dimension of the joint network."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cmIwDscCW1mP"
      },
      "source": [
        "## Transducer Decoding\n",
        "\n",
        "Models which have been trained with CTC can transcribe text simply by performing a regular argmax over the output of their decoder.\n",
        "\n",
        "For transducer-based models, the three networks must operate in a synchronized manner in order to transcribe the acoustic features.\n",
        "\n",
        "The following section of the config describes how to change the decoding logic of the transducer model.\n",
        "\n",
        "\n",
        "**This config can be dropped into any custom transducer model with no modification.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LQjfXJsrIqFJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51c7c275-21c7-49d2-8630-f90516626aa4"
      },
      "source": [
        "print(OmegaConf.to_yaml(cfg.model.decoding))"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "strategy: greedy_batch\n",
            "greedy:\n",
            "  max_symbols: 10\n",
            "beam:\n",
            "  beam_size: 4\n",
            "  score_norm: true\n",
            "  return_best_hypothesis: false\n",
            "  softmax_temperature: 1.0\n",
            "  tsd_max_sym_exp: 10\n",
            "  alsd_max_target_len: 5.0\n",
            "  maes_num_steps: 2\n",
            "  maes_prefix_alpha: 1\n",
            "  maes_expansion_beta: 2\n",
            "  maes_expansion_gamma: 2.3\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6FXtn41wIvu8"
      },
      "source": [
        "-------\n",
        "\n",
        "The most important component at the top level is the `strategy`. It can take one of many values:\n",
        "\n",
        "1) `greedy`: This is sample-level greedy decoding. It is generally exceptionally slow as each sample in the batch will be decoded independently. For publications, this should be used alongside batch size of 1 for exact results.\n",
        "\n",
        "2) `greedy_batch`: This is the general default and should nearly match the `greedy` decoding scores (if the acoustic features are not affected by feature mixing in batch mode). Even for small batch sizes, this strategy is significantly faster than `greedy`.\n",
        "\n",
        "3) `beam`: Runs beam search with the implicit language model of the Prediction model. It will generally be quite slow, and might need some tuning of the beam size to get better transcriptions.\n",
        "\n",
        "4) `tsd`: Time synchronous decoding. Please refer to the paper:                 [Alignment-Length Synchronous Decoding for RNN Transducer](https://ieeexplore.ieee.org/document/9053040) for details on the algorithm implemented. Time synchronous decoding (TSD) execution time grows by the factor T * max_symmetric_expansions. For longer sequences, T is greater and can therefore take a long time for beams to obtain good results. TSD also requires more memory to execute.\n",
        "\n",
        "5) `alsd`: Alignment-length synchronous decoding. Please refer to the paper: [Alignment-Length Synchronous Decoding for RNN Transducer](https://ieeexplore.ieee.org/document/9053040) for details on the algorithm implemented. Alignment-length synchronous decoding (ALSD) execution time is faster than TSD, with a growth factor of T + U_max, where U_max is the maximum target length expected during execution. Generally, T + U_max < T * max_symmetric_expansions. However, ALSD beams are non-unique. Therefore it is required to use larger beam sizes to achieve the same (or close to the same) decoding accuracy as TSD. For a given decoding accuracy, it is possible to attain faster decoding via ALSD than TSD.\n",
        "\n",
        "-------\n",
        "\n",
        "Below, we discuss the various decoding strategies."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PXzY7laMW1oo"
      },
      "source": [
        "### Greedy Decoding\n",
        "\n",
        "When `strategy` is one of `greedy` or `greedy_batch`, an additional subconfig of `decoding.greedy` can be used to set an important decoding value."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "778R5oy6Ipha",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33cca11b-9288-4669-9117-2ceadf093856"
      },
      "source": [
        "print(OmegaConf.to_yaml(cfg.model.decoding.greedy))"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_symbols: 10\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vItXzTbZKwyB"
      },
      "source": [
        "-------\n",
        "\n",
        "This argument `max_symbols` is the maximum number of `target token` decoding steps $u \\le U$ per acoustic timestep $t \\le T$. Note that during training, this was implicitly constrained by the shape of the joint matrix (max_symbols = $U$). However, there is no such $U$ upper bound during inference (we don't have the ground truth $U$).\n",
        "\n",
        "So we explicitly set a heuristic upper bound on how many decoding steps can be performed per acoustic timestep. Generally a value of 5 and above is sufficient."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ebFogfLvW1q9"
      },
      "source": [
        "### Beam Decoding\n",
        "\n",
        "Next, we discuss the subconfig when `strategy` is one of `beam`, `tsd` or `alsd`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w073zT8ILtki",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c2f9f54-3890-46d4-aeee-3dd3b81a5c2e"
      },
      "source": [
        "print(OmegaConf.to_yaml(cfg.model.decoding.beam))"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "beam_size: 4\n",
            "score_norm: true\n",
            "return_best_hypothesis: false\n",
            "softmax_temperature: 1.0\n",
            "tsd_max_sym_exp: 10\n",
            "alsd_max_target_len: 5.0\n",
            "maes_num_steps: 2\n",
            "maes_prefix_alpha: 1\n",
            "maes_expansion_beta: 2\n",
            "maes_expansion_gamma: 2.3\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AvOeRhsULtrx"
      },
      "source": [
        "------\n",
        "\n",
        "There are several important arguments in this section :\n",
        "\n",
        "1) `beam_size`: This determines the beam size for all types of beam decoding strategy. Since this is implemented in PyTorch, large beam sizes will take exorbitant amounts of time.\n",
        "\n",
        "2) `score_norm`: Whether to normalize scores prior to pruning the beam.\n",
        "\n",
        "3) `return_best_hypothesis`: If beam search is being performed, we can choose to return just the best hypothesis or all the hypotheses.\n",
        "\n",
        "4) `tsd_max_sym_exp`: The maximum symmetric expansions allowed per timestep during beam search. Larger values should be used to attempt decoding of longer sequences, but this in turn increases execution time and memory usage.\n",
        "\n",
        "5) `alsd_max_target_len`: The maximum expected target sequence length during beam search. Larger values allow decoding of longer sequences at the expense of execution time and memory.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MkoHp0dQW1tP"
      },
      "source": [
        "## Transducer Loss\n",
        "\n",
        "Finally, we reach the Transducer loss config itself. This section configures the type of Transducer loss itself, along with possible sub-sections.\n",
        "\n",
        "**This config can be dropped into any custom transducer model with no modification.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l3Uk11uHOa4O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "754c11ce-04f3-4a57-9547-24b1f92b017c"
      },
      "source": [
        "print(OmegaConf.to_yaml(cfg.model.loss))"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_name: default\n",
            "warprnnt_numba_kwargs:\n",
            "  fastemit_lambda: 0.001\n",
            "  clamp: -1.0\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1z_mYV9UOk_7"
      },
      "source": [
        "---------\n",
        "\n",
        "The loss config is based on a resolver pattern and can be used as follows:\n",
        "\n",
        "1) `loss_name`: `default` is generally a good option. Will select one of the available resolved losses and match the kwargs from a sub-configs passed via explicit `{loss_name}_kwargs` sub-config. \n",
        "\n",
        "2) `{loss_name}_kwargs`: This sub-config is passed to the resolved loss above and can be used to configure the resolved loss."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7w3Z3-IaRGaz"
      },
      "source": [
        "### WarpRNNT Numba Loss\n",
        "\n",
        "The default transducer loss implemented in NeMo is a Numba port of the excellent CUDA implementation of Transducer Loss found in https://github.com/HawkAaron/warp-transducer.\n",
        "\n",
        "It should suffice for most use cases (CPU / GPU) transducer training."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u9bPDu2-XYPB"
      },
      "source": [
        "### FastEmit Regularization\n",
        "\n",
        "Recently proposed regularization approach - [FastEmit: Low-latency Streaming ASR with Sequence-level Emission Regularization](https://arxiv.org/abs/2010.11148) allows us near-direct control over the latency of transducer models.\n",
        "\n",
        "Refer to the above paper for results and recommendations of `fastemit_lambda`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iGG9UKTZXlme"
      },
      "source": [
        "# Next Steps\n",
        "\n",
        "After that deep dive into how to configure Transducer models, the next tutorial will use one such config to build a transducer model and train it on a small dataset. We will then move on to exploring various decoding strategies and how to evaluate the model."
      ]
    }
  ]
}